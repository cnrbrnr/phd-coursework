\documentclass[10pt]{article}
\usepackage[margin=1.3cm]{geometry}

% Packages
\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage{bbm} 
\usepackage{dutchcal} % [dutchcal, calrsfs, pzzcal] calligraphic fonts
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage[tracking]{microtype}
\usepackage{stmaryrd}

% Palatino for text goes well with Euler
\usepackage[sc,osf]{mathpazo}   % With old-style figures and real smallcaps.
\linespread{1.025}              % Palatino leads a little more leading

% Euler for math and numbers
\usepackage[euler-digits,small]{eulervm}

% Command initialization
\DeclareMathAlphabet{\pazocal}{OMS}{zplm}{m}{n}
\graphicspath{{./images/}}

% Custom Commands
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\var}[1]{\text{Var}\left(#1\right)}
\newcommand{\bp}[1]{\left({#1}\right)}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\1}[1]{\mathbbm{1}_{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\nck}[2]{{#1\choose#2}}
\newcommand{\pc}[1]{\pazocal{#1}}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\newcommand*{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand*{\ceil}[1]{\left\lceil#1\right\rceil}

\DeclareMathOperator{\Var}{Var} \DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\sgn}{sgn}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\newenvironment{indented}[1][2cm]{\setlength{\leftskip}{#1}}{\setlength{\leftskip}{0pt}}

\begin{document}

    \begin{center}
        {\bf\large{MATH 829: FUNCTIONAL ANALYSIS AND QUANTUM MECHANICS}}
        \smallskip
        \hrule
        \smallskip
        {\bf Assignment} 1\hfill {\bf Connor Braun} \hfill {\bf 2024-09-10}
    \end{center}
    \vspace{5pt}
    \begin{center}
        \begin{minipage}{\dimexpr\paperwidth-10cm}
            {\bf Acknowledgements}: Problem 2b was completed with some helpful
            discussion with Osman Bicer. 
        \end{minipage}
    \end{center}
    \noindent{\bf Problem 1} Let $\mbb{X}$ be a vector space over $\mbb{R}$, and
    let $p:\mbb{X}\rightarrow\mbb{R}_{\geq 0}$ be a seminorm on
    $\mbb{X}$.\\[5pt]
    {\bf a)} Prove that $p$ is symmetric.\\[5pt]
    {\bf Proof}. Let $x\in\mbb{X}$. Since $p$ is absolutely homogeneous by
    virtue of being a seminorm, we get
    $p(-x)=|-1|p(x)=p(x)$.\hfill{$\qed$}\\[5pt]
    {\bf b)} Prove that $|p(x)-p(y)|\leq p(x-y)$ for any $x,y\in\mbb{X}$.\\[5pt]
    {\bf Proof}. Take any $x,y\in\mbb{X}$. Then we have 
    \begin{align*}
        p(x)=p(x-y+y)\leq p(x-y)+p(y)\quad&\Rightarrow\quad p(x)-p(y)\leq p(x-y)\tag{1}\\
        p(y)=p(y-x+x)\leq p(y-x)+p(x)=p(x-y)+p(x)\quad&\Rightarrow\quad -(p(x)-p(y))\leq p(x-y).\tag{2}
    \end{align*}
    Combining (1) and (2), we get $|p(x)-p(y)|\leq p(x-y)$, as
    desired.\hfill{$\qed$}\\[5pt]
    {\bf c)} Let $E=\{x\in\mbb{X}:p(x)=0\}$ be the kernel of the seminorm $p$.
    Prove that $E$ is closed. That is, prove that for any $(x_n)_{n\geq
    1}\subset E$ with $\lim_{n\rightarrow\infty}p(x_n-x)=0$ for some
    $x\in\mbb{X}$, it follows that $x\in E$.\\[5pt]
    {\bf Proof}. Take $(x_n)_{n\geq 1}$ as prescribed, converging to some
    $x\in\mbb{X}$ with respect to $p$. By the aforeshown reverse triangle
    inequality, we produce the bound
    \begin{align*}
        |p(x_n)-p(x)|\leq p(x_n-x)\quad\Rightarrow\quad |p(x)|\leq p(x_n-x)
    \end{align*}
    where the implication follows $x_n\in E$ $\forall n\geq 1$. Taking the limit
    as $n\rightarrow\infty$: we obtain
    \[|p(x)|\leq\lim_{n\rightarrow\infty}p(x_n-x)=0\] so, indeed, $p(x)=0$
    (since $p$ is nonnegative), which means the limit $x\in
    E$.\hfill{$\qed$}\\[5pt]
    {\bf d)} Define a {\it pseudo-metric} $d:\mbb{X}\times\mbb{X}\rightarrow
    \mbb{R}$ as $d(x,y)=p(x-y)$. Prove that $d$ is a metric if and only if $p$
    is a norm.\\[5pt]
    {\bf Proof}. Suppose that $d$ is a metric, and further that $x\in\mbb{X}$
    satisfies $p(x)=0$. Then $0=p(x)=p(x-0)=d(x,0)$, implying that $x=0$. Of
    course, $p$ is already nonnegative, absolutely homogeneous and satisfies the
    triangle inequality, so this is sufficient to certify $p$ as a proper
    norm.\\[5pt]
    For the reverse direction, let us suppose that $p$ is a norm. Fix arbitrary
    elements $x,y,z\in\mbb{X}$. Then, we first have $d(x,x)=p(x-x)=p(0)=0$.
    Alternatively, if we assume $d(x,y)=0$, then $p(x-y)=0$, so $x=y$ by the
    normhood of $p$. Clearly, $d(x,y)=p(x-y)\geq 0$ regardless of
    $x,y\in\mbb{X}$. Symmetry of $d$ is also simple:
    $d(x,y)=p(x-y)=p(y-x)=d(y,x)$. Finally, for the triangle inequality:
    \begin{align*}
        d(x,y)=p(x-y)=p(x-z+z-y)\leq p(x-z)+p(z-y)=d(x,z)+d(z,y)
    \end{align*}
    as required. Thus, $p$ a norm $\Rightarrow$ $d$ is a metric, and vise
    versa.\hfill{$\qed$}\\[5pt]
    {\bf Problem 2} Recall the normed vector spaces $(\ell_p,\|\cdot\|_p)$,
    where $1\leq p\leq \infty$.\\[5pt]
    {\bf a)} Show that if $1\leq p,\leq q<\infty$, then $\|x\|_q\leq
    \|x\|_p$.\\[5pt]
    {\bf Solution}. Fix $1\leq p<q<\infty$ (the case of $q=p$ holds trivially)
    and take $x\in\ell_p$, supposing first that $\|x\|_p\leq 1$. That is,
    $\sum_{j=1}^\infty|x_j|^p\leq 1$, so in particular, $|x_j|\leq 1$ $\forall
    j\geq 1$. But then $|x_j|^p\geq |x_j|^q$ $\forall j\geq 1$, so
    $\sum_{j=1}^\infty|x_j|^q\leq \sum_{j=1}^\infty|x_j|^p\leq 1$, and further
    $(\sum_{j=1}^\infty|x_j|^q)^{1/q}\leq (\sum_{j=1}^\infty|x_j|^p)^{1/p}$,
    i.e. $\|x\|_q\leq\|x\|_p$ (which holds since both series are $\leq 1$, and
    $q>p$).\\[5pt]
    More generally, for $x\in\ell_p$ such that $x\neq 0$ (which is also trivial:
    $\|0\|_p=0\geq 0=\|0\|_q$) so that $0<\|x\|_p<\infty$, we consider
    $\tilde{x}:=\tfrac{1}{\|x\|_p}x$, which satisfies
    $\|\tilde{x}\|_p=\tfrac{1}{\|x\|_p}\|x\|_p=1$. But then
    \begin{align*}
        \|\tilde{x}\|_q\leq 1\quad\Rightarrow\quad\frac{1}{\|x\|_p}\|x\|_q\leq 1\quad\Rightarrow\quad \|x\|_q\leq\|x\|_p
    \end{align*}
    with the first expression following the preliminary
    case.\hfill{$\qed$}\\[5pt]
    {\bf b)} Part (a) shows that $\ell_p\subseteq\ell_q$ for $p<q$. Determine
    whether either of the statements
    \begin{align*}
        \ell_p=\bigcap_{q>p}\ell_q\tag{$\mathfrak{A}$}\\
        \ell_q=\bigcup_{1\leq p<q}\ell_p\tag{$\mathfrak{B}$}
    \end{align*}
    are true, and provide a proof.\\[5pt]
    {\bf Solution}. Both statements are false, and we will begin with the
    relatively simpler counterexample for $\mathfrak{A}$. Consider the sequence
    $x=(\tfrac{1}{n^{1/p}})_{n\geq 1}$. Then $x\in\ell_q$ for all $q>p$ since
    \begin{align*}
        \|x\|_q^q=\sum_{n\geq 1}\frac{1}{n^{q/p}}<\infty
    \end{align*}
    because $q/p>1$. However, $\|x\|^p_p=\sum_{n\geq 1}\tfrac{1}{n}$ diverges,
    so $x\notin\ell_p$, disproving $\mathfrak{A}$.\\[5pt]
    As a counterexample to $\mathfrak{B}$, fix some $q>p$ and consider the
    sequence $x=(x_n)_{n\geq 1}$ with
    \begin{align*}
        x_n=\frac{1}{[(n+2)(\log(n+2))^2]^{1/q}},\quad n\geq 1,\quad\text{and}\quad\|x\|_q^q=\sum_{n\geq 1}\frac{1}{(n+2)(\log(n+2))^2}
    \end{align*}
    To show $x\in\ell_q$, we will use the integral test (since the $x_j$ can be
    interpretted by a continuous, decreasing function on $[1,\infty)$):
    \begin{align*}
        \int_1^\infty\frac{dx}{(x+2)(\log(x+2))^2}=\int_{\log(3)}^\infty\frac{(x+2)du}{(x+2)u^2}&=\int_{\log(3)}^\infty\frac{du}{u^2}\tag{change of variables $u=\log(x+2)$}\\
        &=-\frac{1}{u}\bigg|^\infty_{\log(3)}\\
        &=\lim_{u\rightarrow\infty}-\frac{1}{u}+\frac{1}{\log(3)}<\infty
    \end{align*}
    which implies that $\|x\|_q^q<\infty$, so $x\in\ell_q$. We next claim that
    for any $1\leq p<q$, $\|x\|_p=\infty$. First, observe that
    $\log(n+2)>\log(e)=1$ for all $n\geq 1$. Then, whenever $0<m<1$ we get
    \begin{align*}
        \frac{1}{[(n+2)(\log(n+2))^2]^m}=\frac{1}{(n+2)^m(\log(n+2))^{2m}}\geq\frac{1}{(n+2)^m(\log(n+2))^2},\quad n\geq 1.
    \end{align*}
    In particular, this says $\sum_{n\geq
    1}\tfrac{1}{[(n+2)(\log(n+2))^2]^m}\geq\sum_{n\geq
    1}\frac{1}{(n+2)^m(\log(n+2))^2}$. Fixing such an $m\in(0,1)$, let us once
    again use the integral test to determine the convergence of the latter
    series (this is once again justified by the existence of a continuous,
    decreasing interpolant):
    \begin{align*}
        \int_1^\infty\frac{dx}{(x+2)^m(\log(x+2))^2}&=\int_{\log(3)}^\infty\frac{(x+2)^{1-m}du}{u^2}\tag{change of variables $u=\log(x+2)$}\\
        &=\int_{\log(3)}^\infty\frac{e^{u(1-m)}du}{u^2}\tag{$(x+2)=e^u$}\\
        &=\frac{-e^{u(1-m)}}{u}\bigg|_{\log(3)}^\infty+\int_{\log(3)}^\infty\frac{(1-m)e^{u(1-m)}du}{u}\tag{integration by parts}\\
        &\geq \lim_{u\rightarrow\infty}-\frac{e^{u(1-m)}}{u}+\frac{3^{(1-m)}}{\log(3)}\tag{$\int_{\log(3)}^\infty\tfrac{(1-m)e^{u(1-m)}du}{u}\geq 0$}\\
        &=\infty
    \end{align*} 
    where the limit is easily evaluated with L'H\^opital's rule given the
    indeterminate $\tfrac{\infty}{\infty}$. Since this integral diverges, so too
    does the series; that is
    \begin{align*}
        \sum_{n\geq 1}\frac{1}{[(n+2)(\log(n+2))^2]^m}=\infty,\quad 0<m<1.
    \end{align*}
    Of course, with $q>p\geq 1$, this means that
    \begin{align*}
        \|x\|_p^p=\sum_{n\geq 1}\frac{1}{[(n+2)(\log(n+2))^2]^{p/q}}=\infty,\quad\text{since $0<p/q<1$.}
    \end{align*}
    In total, we've found a sequence $x$ with $x\in\ell_q$, but
    $x\notin\bigcup_{1\leq p<q}\ell_p$. Thus, $\mathfrak{B}$ is
    false.\hfill{$\qed$}\\[5pt]
    {\bf Problem 3}. Recall the space $(\ell_2,\|\cdot\|_2)$, where
    $\ell_2=\{x=(x_n)_{n\geq 1}:\|x\|_2<\infty\}$ and $\|x\|_2=\left(\sum_{n\geq
    1}|x_n|^2\right)^{1/2}$. Consider the set $V$ given by
    \begin{align*}
        V:=\left\{x=(x_n)_{n\geq 1}:\sum_{n=1}^\infty n^2|x_n|^2\leq 1\right\}.
    \end{align*}
    {\bf a)} Prove $V$ is a convex subset of $\ell_2$.\\[5pt]
    {\bf Proof}. For any $x\in V$, we have $\|x\|_2=\left(\sum_{n\geq
    1}|x_n|^2\right)^{1/2}<\left(\sum_{n\geq 1}n^2|x_n|^2\right)^{1/2}=1$, so
    indeed, $x\in\ell_2$ and thus $V\subseteq\ell_2$. To demonstrate convexity,
    take $\lambda\in[0,1]$ and some $x,y\in V$. Then the convex combination
    $\lambda x+(1-\lambda)y\in V$ too, as the following shows:
    \begin{align*}
        \sum_{n\geq 1}n^2|\lambda x_n+(1-\lambda)y_n|^2&\leq \sum_{n\geq 1}n^2(|\lambda x_n|+|(1-\lambda)y_n|)^2\tag{3}\\
        &=\lambda^2\left[\sum_{n\geq 1}n^2|x_n|^2\right]+(1-\lambda)^2\left[\sum_{n\geq 1}n^2|y_n|^2\right]+2\lambda(1-\lambda)\left[\sum_{n\geq 1}n^2|x_ny_n|\right]\\
        &\leq\lambda^2+(1-\lambda)^2+2\lambda(1-\lambda)\left[\sum_{n\geq 1}|nx_nny_n|\right]\tag{4}\\ 
        &\leq \lambda^2+(1-\lambda)^2+2\lambda(1-\lambda)\left(\sum_{n\geq 1}n^2|x_n|^2\right)^{1/2}\left(\sum_{n\geq 1}n^2|y_n|^2\right)^{1/2}\tag{5}\\
        &\leq \lambda^2+(1-\lambda)^2+2\lambda(1-\lambda)\\
        &=(\lambda+(1-\lambda))^2\\
        &=1.
    \end{align*}
    Elaborating, (3) follows the triangle inequality, (4) the assumption that
    $x,y\in V$, and (5) by H\"older's inequality with conjugate pair
    $(2,2)$.\hfill{$\qed$}\\[5pt]
    {\bf b)} Show that $V$ is centrally symmetric.\\[5pt]
    {\bf Solution}. Take $x\in V$. Then $\sum_{n\geq 1}n^2|-x_n|^2=\sum_{n\geq
    1}n^2|x_n|^2\leq 1$. Thus, $x\in V$ $\Rightarrow$ $-x\in
    V$.\hfill{$\qed$}\\[5pt]
    {\bf c)} Show that $V$ has an empty interior by solving the next three
    subproblems.\\[5pt]
    {\bf c.i)} Suppose, for the purposes of deriving a contradiction, that
    $S^\prime=B_r(x_0)\subset V$ for some $x_0\in V$, $r>0$. Show this implies
    $S^{\prime\prime}=B_r(-x_0)$, and that these facts further imply
    $B_r(0)\subset V$.\\[5pt]
    {\bf Proof}. Let us suppose by way of deriving a contradition that
    $B_r(x_0)\subset V$ for some $x_0\in V$, $r>0$, as prescribed. Then $-x_0\in
    V$ by the central symmetry of $V$, and for any $x\in B_r(-x_0)$ we get
    \begin{align*}
        \|x-(-x_0)\|_2<r\quad\Rightarrow\quad|-1|\|(-x)-x_0\|_2<r\quad\Rightarrow\quad (-x)\in B_r(x_0)\subset V
    \end{align*}
    whereby the central symmetry of $V$, $-x\in V$ $\Rightarrow$  $x\in V$, so
    $B_r(-x_0)\subset V$ as well. To show $B_r(0)\subset V$, observe first that
    $0\in V$ (since $\sum_{n\geq 1}n^2|0|=0\leq 1$) and consider a point $x\in
    B_r(0)$ so that $\|x\|_2<r$. Then $x+x_0\in B_r(x_0)$ and $x-x_0\in
    B_r(-x_0)$, since $\|x+x_0-x_0\|<r$ and $\|x-x_0-(-x_0)\|<r$ (respectively).
    But $V$ is convex, so the convex combination
    \begin{align*}
        \frac{1}{2}(x+x_0)+\frac{1}{2}(x-x_0)=x
    \end{align*}
    is also in $V$. That is, $B_r(0)\subset V$, as desired.\hfill{$\qed$}\\[5pt]
    {\bf c.ii)} Use (c.i) to claim that on every ray emanating from $0\in V$
    there must lie a segment belonging entirely to $V$.\\[5pt]
    {\bf Proof}. Let $x\in\ell_2$, $x\neq 0$ (for otherwise the ray is trivially
    a subset of $B_r(0)$) and $\Lambda:=\{\lambda x:\lambda\geq 0\}$. Provided
    $0\leq \lambda<\tfrac{r}{\|x\|_2}$, we get
    \begin{align*}
        \|\lambda x\|_2<\frac{r}{\|x\|_2}\|x\|_2=r,\quad\Rightarrow\quad \lambda x\in B_r(0)\subset V
    \end{align*}
    so that $\Lambda^\prime:=\{\lambda
    x:\lambda\in[0,\tfrac{r}{\|x\|_2})\}\subset\Lambda$ defining a segment of
    the ray emanating from $0$ in the direction of $x$ is satisfies
    $\Lambda^\prime\subset B_r(0)\subset V$.\hfill{$\qed$}\\[5pt]
    {\bf c.iii)} Use the ray connecting $0$ and $x=(n^{-1})_{n\geq 1}$ to derive
    a contradition.\\[5pt]
    {\bf Solution}. First, observe that $x\in\ell_2$, since
    $\|x\|_2^2=\sum_{n\geq 1}\tfrac{1}{n^2}<\infty$. Then by (c.ii), $\exists
    \lambda\geq 0$ so that $\lambda x\in B_r(0)\subset V$. In particular, we may
    take $\lambda>0$ since $\tfrac{r}{\|x\|_2}>0$. From this we obtain
    \begin{align*}
        \sum_{n\geq 1}n^2\|\lambda\frac{1}{n}|^2\leq 1\quad\Rightarrow\quad\lambda\sum_{n\geq 1}\frac{n^2}{n^2}\leq 1\quad\Rightarrow\quad\lambda\cdot\infty\leq 1\quad\lightning
    \end{align*}
    which is a clear contradiction. To resolve this, it must be the case that
    $B_r(x_0)\nsubseteq V$ for any choice of $x_0\in\ell_2$, $r>0$. That is, $V$
    has empty interior.\hfill{$\qed$}\\[5pt]
    {\bf Problem 4}. Let $X$ be a vector space over $\mbb{R}$. A set
    $\Upsilon\subset X$ is called {\it balanced} if and only if
    $\lambda\Upsilon\subset\Upsilon$ for every $\lambda\in[-1,1]$. A set is
    called {\it absolutely convex} if and only if it is convex and balanced. A
    set $\Upsilon \subset X$ is called {\it absorbing} if and only if $\forall
    x\in X$, $\exists \lambda >0$ such that $x\in\lambda\Upsilon$. For $\Upsilon
    \subset X$, let $q_\Upsilon:X\rightarrow \mbb{R}\cup\{\infty\}$ be defined
    as $q_\Upsilon(x)=\inf\{\lambda>0:x\in\lambda\Upsilon\}$. \\[5pt]
    {\bf a)} Suppose that $\Upsilon, Z\subset X$ are two convex absorbing sets
    with $\Upsilon\subset Z$. Prove that $q_\Upsilon(x)\geq q_Z(x)$ $\forall
    x\in X$.\\[5pt]
    {\bf Proof}. Take $x\in X$. Since $\Upsilon$ is absorbing,
    $\exists\lambda>0$ so that $x\in\lambda\Upsilon$, impliying that
    $\exists\upsilon\in\Upsilon$ such that $x=\lambda\upsilon$. But
    $\upsilon\in\Upsilon\subset Z$, so $\upsilon\in Z$, and therefore
    $x\in\lambda Z$ too. That is,
    \[\{\lambda>0:x\in\lambda\Upsilon\}\subseteq\{\lambda>0:x\in\lambda
    Z\}\quad\Rightarrow\quad\inf\{\lambda>0:x\in\lambda\Upsilon\}\geq
    \inf\{\lambda>0:x\in\lambda Z\}\quad\Rightarrow\quad q_\Upsilon(x)\geq
    q_Z(x).\tag*{$\qed$}\] {\bf b)} Prove that if
    $\Upsilon_1,\Upsilon_2,\dots,\Upsilon_n$ are convex and absorbing, then the
    intersection $\bigcap_{j=1}^n\Upsilon_j$ is absorbing. Provide an example of
    two non-convex absorbing subsets of $\mbb{R}$ whose intersection is not
    absorbing.\\[5pt]
    {\bf Soluiton}. Let us first prove a preliminary claim: $0<\lambda_1\leq
    \lambda_2$ $\Rightarrow$ $\lambda_1\Xi\subseteq\lambda_2\Xi$ for any $\Xi$
    convex, absorbing. To show this, first note $0\in\Xi$, since $\Xi$ is
    absorbing (this is necessary since otherwise $\lambda\xi>0$ for any
    $\lambda>0$, $\xi\in\Xi$). Now take $x\in\lambda_1\Xi$, so that
    $x=\lambda_1\xi$ for some $\xi\in\Xi$. Then by convexity of $\Xi$, 
    \begin{align*}
        \frac{\lambda_1}{\lambda_2}\xi+(1-\frac{\lambda_1}{\lambda_2})0\in\Xi\quad\Rightarrow\quad\frac{\lambda_1}{\lambda_2}\xi\in\Xi,\quad\text{so}\quad\lambda_2(\frac{\lambda_1}{\lambda_2}\xi)=\lambda_1\xi=x
    \end{align*}
    implying that $x\in\lambda_2\Xi$, thus proving the initial claim. Now, since
    each of $\Upsilon_j$, $1\leq j\leq n$ are absorbing, $\exists
    (\lambda_j)_{j=1}^n$ so that $x\in\lambda_j\Upsilon_j$ $\forall j$, and
    $\forall x\in X$. Then define
    $\lambda^\ast:=\max\{\lambda_1,\lambda_2,\dots,\lambda_n\}$ so that
    $x\in\lambda^\ast\Upsilon_j$ for $1\leq j\leq n$, which follows from the
    initial claim. By definition, $\exists(\upsilon_j)_{j=1}^n$ where
    $\upsilon_j\in\Upsilon_j$ satisfies $x=\lambda^\ast\upsilon_j$ for $1\leq
    j\leq n$. However, from this we get $\upsilon_j=\tfrac{x}{\lambda^\ast}$ for
    $1\leq j\leq n$, and so $\upsilon_1=\upsilon_2=\cdots=\upsilon_n$.
    Proceeding with $\upsilon:=\upsilon_1$, we further get
    $\upsilon\in\Upsilon_j$ for $1\leq j\leq n$, so
    $\upsilon\in\bigcap_{j=1}^n\Upsilon_j$ and $\lambda^\ast\upsilon=x$, where
    $x\in X$ was arbitrary. That is, $\bigcap_{j=1}^n\Upsilon_j$ is itself
    absorbing, and we are done.\\[5pt]
    For the desired counterexample, consider $\mc{A}:=[-2,-1)\cup\{0\}\cup(1,2]$
    and $\mc{B}:=[-3,-2)\cup\{0\}\cup(2,3]$. Clearly, neither are convex since
    $2,0\in\mc{A}$ but $\tfrac{1}{2}2+\tfrac{1}{2}0=1\notin\mc{A}$, and
    $3,0\in\mc{B}$ but $\tfrac{2}{3}3+\tfrac{1}{3}0=2\notin\mc{B}$. Both are
    absorbing, though. To see this, take $x\in\mbb{R}$. If $x=0$, then clearly
    $x\in 1\mc{A},1\mc{B}$, so let us consider the cases where $x>0$ and $x<0$
    separately. First, when $x>0$, $x=\tfrac{x}{2}2$ and $x=\tfrac{x}{3}3$, so
    $x\in\tfrac{x}{2}\mc{A}$ and $x\in\tfrac{x}{3}\mc{B}$. Similarly, when
    $x<0$, we have $x=\tfrac{|x|}{2}(-2)$ and $x=\tfrac{|x|}{3}(-3)$, so
    $x\in\tfrac{|x|}{2}\mc{A}$ and $x\in\tfrac{|x|}{3}\mc{B}$. That is, no matter the $x\in\mbb{R}$, we
    can find $\lambda_1,\lambda_2>0$ so that $x\in\lambda_1\mc{A}$ and $x\in\lambda_2\mc{B}$, so both sets are absorbing.
    However, $\mc{A}\cap\mc{B}=\{0\}$, and $1\neq\lambda\cdot 0$ no matter the $\lambda>0$, so $\mc{A}\cap\mc{B}$ is not absorbing.
    Thus, the convexity requirement is not dispensible.\hfill{$\qed$}\\[5pt]
    {\bf c)} Let $\Upsilon\subset X$ be absolutely convex and absorbing. Prove that $q_\Upsilon:\mbb{X}\rightarrow\mbb{R}$ is a seminorm.\\[5pt]
    {\bf Proof}. Fixing $x\in X$, we know $\Lambda_x:=\{\lambda>0:x\in\lambda\Upsilon\}\neq\emptyset$ since $\Upsilon$ is absorbing, so $0\leq q_\Upsilon(x)<\infty$ for any $x\in X$
    (the nonnegativity follows from $\Lambda_x\subseteq(0,\infty)$). Also, $\Lambda_0=(0,\infty)$, so $q_\Upsilon(0)=0$.\\[5pt]
    The function $q_\Upsilon$ is absolutely homogeneous if and only if $q_\Upsilon(\beta x)=|\beta|q_\Upsilon(x)$ for all $\beta\in\mbb{R}$, $\beta\neq 0$, $x\in X$, which we will show next. Note first that $(-1)\Upsilon\subseteq\Upsilon$ since $\Upsilon$ is balanced, and that the case where $\beta=0$ is trivial, since $q_\Upsilon(0x)=0=|0|q_\Upsilon(x)$. Then, define $\sgn:\mbb{R}\rightarrow\{-1,1\}$ with
    \[\sgn(\beta)=\begin{cases}
        1, \quad&\text{if $\beta\geq 0$}\\
        -1,\quad&\text{if $\beta<0$}
    \end{cases}\]
    and note that $\beta=\sgn(\beta)|\beta|$ $\forall\beta\in\mbb{R}$. Fixing $\beta\in\mbb{R}\setminus\{0\}$, we will demonstrate that $\beta x\in\lambda\Upsilon$ $\Leftrightarrow$ $x\in\tfrac{\lambda}{|\beta|}\Upsilon$, where $\lambda>0$.
    Suppose first that $\beta x\in\lambda\Upsilon$. Then $\exists\upsilon\in\Upsilon$ such that $\beta x=\lambda\upsilon$, so
    \[x=\frac{\lambda}{\beta}\upsilon=\frac{\lambda}{|\beta|}\sgn(\beta)\upsilon\]
    but $\sgn(\beta)\upsilon\in\Upsilon$ too, since $(-1)\Upsilon\subseteq\Upsilon$, and thus $x\in\tfrac{\lambda}{|\beta|}\Upsilon$. Conversely, beginning with $x\in\frac{\lambda}{|\beta|}$ for some $\beta\neq 0$ and $\lambda>0$, we get $x=\tfrac{\lambda}{|\beta|}\upsilon^\prime$ for some $\upsilon^\prime\in\Upsilon$,
    and $\beta x=\beta\tfrac{\lambda}{|\beta|}\upsilon^\prime=\beta\tfrac{\lambda}{\sgn(\beta)|\beta|}\sgn(\beta)\upsilon^\prime=\lambda(\sgn(\beta)\upsilon^\prime)$. But $\upsilon:=\sgn(\beta)\upsilon^\prime\in\Upsilon$, so $\beta x=\lambda\upsilon$ and thus $\beta x\in\lambda\Upsilon$. Equipped with this characterization absolute homogeneity follows directly:
    \begin{align*}
        q_\Upsilon(\beta x)=\inf\{\lambda>0:\beta x\in\lambda\Upsilon\}=\inf\{\lambda>0:x\in(\lambda/|\beta|)\Upsilon\}=\inf\{|\beta|(\lambda/|\beta|)>0:x\in(\lambda/|\beta|)\Upsilon\}=|\beta|\inf\{\lambda^\prime>0:x\in\lambda^\prime\Upsilon\}=|\beta|q_{\Upsilon}(x).
    \end{align*}
    For the last step, we must show that $q_\Upsilon$ satisfies the triangle inequality. For this, fix $x,y\in X$, and let $q_\Upsilon(x)=\lambda_x$ and $q_\Upsilon(y)=\lambda_y$, such that $x=\lambda_x\upsilon_x$ and $y=\lambda_y\upsilon_y$ for some $\upsilon_x,\upsilon_y\in\Upsilon$.
    But $\Upsilon$ is convex, so the convex combination
    \begin{align*}
        \frac{\lambda_x}{\lambda_x+\lambda_y}\upsilon_x+\frac{\lambda_y}{\lambda_x+\lambda_y}\upsilon_y\in\Upsilon\quad\Rightarrow\quad \frac{1}{\lambda_x+\lambda_y}(\lambda_x\upsilon_x+\lambda_y\upsilon_y)\in\Upsilon\quad\Rightarrow\quad (x+y)\in(\lambda_x+\lambda_y)\Upsilon
    \end{align*}
    where the last implication follows from $\beta z\in\lambda\Upsilon$ $\Leftrightarrow$ $z\in\tfrac{\lambda}{|\beta|}\Upsilon$ for $z\in X$, $\beta\in\mbb{R}\setminus\{0\}$. This tells us that $\lambda_x+\lambda_y\in\Lambda_{x+y}$, so we can obtain
    \begin{align*}
        q_\Upsilon(x+y)=\inf\{\lambda>0:x+y\in\lambda\Upsilon\}=\inf\Lambda_{x+y}\leq \lambda_x+\lambda_y=q_\Upsilon(x)+q_{\Upsilon}(y).
    \end{align*}
    Since $q_\Upsilon$ is nonegative, absolutely homogeneous and satisfies the triangle inequality, it is a seminorm.\hfill{$\qed$}  
\end{document}